{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WGAN_DIV.ipynb","provenance":[],"collapsed_sections":["YrYtB5WwfhKH","-_Zbdg3pUgrv"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y2UUXfEJMJcZ","executionInfo":{"status":"ok","timestamp":1637692172577,"user_tz":-540,"elapsed":561,"user":{"displayName":"‍노혜능[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02012322631675297139"}},"outputId":"55e88788-9ba1-40a4-804e-91a52d08e15b"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"YrYtB5WwfhKH"},"source":["### Pytorch ImageFolder 객체에 맞도록 datafolder 구성 (레이블 필요한 경우)"]},{"cell_type":"code","metadata":{"id":"JeWLDWVnNUl3"},"source":["# filename 에 class 가 바로 대응된 dictionary 파일 읽어옴\n","import pickle\n","\n","# dataset에서 file들 가져옴 \n","import os\n","import shutil\n","\n","with open('/content/drive/Shareddrives/machine_learning_in_practice/Analog-PILGI-to-DIgital/GAN/data/pFileNameToClass.pickle','rb') as fw:\n","    pFileNameToClass = pickle.load(fw) # O(1) 로 바로 class 찾을 수 있다.\n","\n","# 인쇄체 데이터 모은 폴더의 이미지들 file list 받음\n","path = \"/content/drive/Shareddrives/machine_learning_in_practice/Analog-PILGI-to-DIgital/GAN/data/printed\"\n","file_list = os.listdir(path) # 35765 -> augmentation 필요\n","\n","# imageFolder 객체에 맞도록 datafolder 구성\n","pretrain_dir_path = \"/content/drive/Shareddrives/machine_learning_in_practice/Analog-PILGI-to-DIgital/GAN/data/pretrainDataset\"\n","os.makedirs(pretrain_dir_path, exist_ok=True)\n","\n","for filename in file_list:\n","    label = pFileNameToClass[filename]\n","    folder_path = \"/content/drive/Shareddrives/machine_learning_in_practice/Analog-PILGI-to-DIgital/GAN/data/pretrainDataset/\" + str(label)\n","    os.makedirs(folder_path, exist_ok=True)\n","    shutil.move(path + '/' + filename, folder_path + '/' + filename)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GCmfC1XoMYwi"},"source":["## Pretrain_DataLoader"]},{"cell_type":"markdown","metadata":{"id":"-_Zbdg3pUgrv"},"source":["#### utils for preprocessing"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":348},"id":"XdcB7NHsjQ2s","executionInfo":{"status":"ok","timestamp":1637692159499,"user_tz":-540,"elapsed":11231,"user":{"displayName":"‍노혜능[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02012322631675297139"}},"outputId":"9582babd-f273-4af7-f2ce-fcb10ceecc24"},"source":["!pip install scipy==1.2.0"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scipy==1.2.0\n","  Downloading scipy-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (26.6 MB)\n","\u001b[K     |████████████████████████████████| 26.6 MB 1.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.2.0) (1.19.5)\n","Installing collected packages: scipy\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.4.1\n","    Uninstalling scipy-1.4.1:\n","      Successfully uninstalled scipy-1.4.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","jax 0.2.25 requires scipy>=1.2.1, but you have scipy 1.2.0 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed scipy-1.2.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["scipy"]}}},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"Pn5thW08i8O_","executionInfo":{"status":"ok","timestamp":1637692176533,"user_tz":-540,"elapsed":938,"user":{"displayName":"‍노혜능[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02012322631675297139"}}},"source":["import imageio\n","import scipy.misc as misc\n","import numpy as np\n","from io import BytesIO\n","from PIL import Image\n","from scipy.misc import imresize\n","import cv2\n","import matplotlib.pyplot as plt"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"3eaVoZXPfidT","executionInfo":{"status":"ok","timestamp":1637692177474,"user_tz":-540,"elapsed":4,"user":{"displayName":"‍노혜능[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02012322631675297139"}}},"source":["def tight_crop_image(img, verbose=False, resize_fix=False):\n","    row_img_size = img.shape[0]\n","    col_img_size = img.shape[1]\n","    col_sum = np.where(col_img_size - np.sum(img, axis=0) > 1)\n","    row_sum = np.where(row_img_size - np.sum(img, axis=1) > 1)\n","    y1, y2 = row_sum[0][0], row_sum[0][-1]\n","    x1, x2 = col_sum[0][0], col_sum[0][-1]\n","    cropped_image = img[y1:y2, x1:x2]\n","    cropped_image_size = cropped_image.shape\n","    \n","    if verbose:\n","        print('(left x1, top y1):', (x1, y1))\n","        print('(right x2, bottom y2):', (x2, y2))\n","        print('cropped_image size:', cropped_image_size)\n","        \n","    if type(resize_fix) == int:\n","        origin_h, origin_w = cropped_image.shape\n","        if origin_h > origin_w:\n","            resize_w = int(origin_w * (resize_fix / origin_h))\n","            resize_h = resize_fix\n","        else:\n","            resize_h = int(origin_h * (resize_fix / origin_w))\n","            resize_w = resize_fix\n","        if verbose:\n","            print('resize_h:', resize_h)\n","            print('resize_w:', resize_w, \\\n","                  '[origin_w %d / origin_h %d * target_h %d]' % (origin_w, origin_h, target_h))\n","        \n","        # resize\n","        cropped_image = imresize(cropped_image, (resize_h, resize_w))\n","        cropped_image = normalize_image(cropped_image)\n","        cropped_image_size = cropped_image.shape\n","        if verbose:\n","            print('resized_image size:', cropped_image_size)\n","        \n","    elif type(resize_fix) == float:\n","        origin_h, origin_w = cropped_image.shape\n","        resize_h, resize_w = int(origin_h * resize_fix), int(origin_w * resize_fix)\n","        if resize_h > 120:\n","            resize_h = 120\n","            resize_w = int(resize_w * 120 / resize_h)\n","        if resize_w > 120:\n","            resize_w = 120\n","            resize_h = int(resize_h * 120 / resize_w)\n","        if verbose:\n","            print('resize_h:', resize_h)\n","            print('resize_w:', resize_w)\n","        \n","        # resize\n","        cropped_image = imresize(cropped_image, (resize_h, resize_w))\n","        cropped_image = normalize_image(cropped_image)\n","        cropped_image_size = cropped_image.shape\n","        if verbose:\n","            print('resized_image size:', cropped_image_size)\n","    \n","    return cropped_image"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"bcWvfgTqfjk3","executionInfo":{"status":"ok","timestamp":1637692178089,"user_tz":-540,"elapsed":7,"user":{"displayName":"‍노혜능[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02012322631675297139"}}},"source":["def add_padding(img, image_size=128, verbose=False, pad_value=None):\n","    height, width = img.shape\n","    if not pad_value:\n","        pad_value = img[0][0]\n","    if verbose:\n","        print('original cropped image size:', img.shape)\n","    \n","    # Adding padding of x axis - left, right\n","    pad_x_width = (image_size - width) // 2\n","    pad_x = np.full((height, pad_x_width), pad_value, dtype=np.float32)\n","    img = np.concatenate((pad_x, img), axis=1)\n","    img = np.concatenate((img, pad_x), axis=1)\n","    \n","    width = img.shape[1]\n","\n","    # Adding padding of y axis - top, bottom\n","    pad_y_height = (image_size - height) // 2\n","    pad_y = np.full((pad_y_height, width), pad_value, dtype=np.float32)\n","    img = np.concatenate((pad_y, img), axis=0)\n","    img = np.concatenate((img, pad_y), axis=0)\n","    \n","    # Match to original image size\n","    width = img.shape[1]\n","    if img.shape[0] % 2:\n","        pad = np.full((1, width), pad_value, dtype=np.float32)\n","        img = np.concatenate((pad, img), axis=0)\n","    height = img.shape[0]\n","    if img.shape[1] % 2:\n","        pad = np.full((height, 1), pad_value, dtype=np.float32)\n","        img = np.concatenate((pad, img), axis=1)\n","\n","    if verbose:\n","        print('final image size:', img.shape)\n","    \n","    return img"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q9XPEfC_ftpe","executionInfo":{"status":"ok","timestamp":1637692178091,"user_tz":-540,"elapsed":7,"user":{"displayName":"‍노혜능[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02012322631675297139"}}},"source":["def centering_image(img, image_size=128, verbose=False, resize_fix=False, pad_value=None):\n","    if not pad_value:\n","        pad_value = img[0][0]\n","    cropped_image = tight_crop_image(img, verbose=verbose, resize_fix=resize_fix)\n","    height, width = cropped_image.shape\n","    if height > image_size: # dsize=(640, 480)\n","        cropped_image = cv2.resize(cropped_image, dsize=(width, 128))\n","    height, width = cropped_image.shape\n","    if width > image_size:\n","        cropped_image = cv2.resize(cropped_image, dsize=(128, height))\n","    centered_image = add_padding(cropped_image, image_size=image_size, verbose=verbose, pad_value=pad_value)\n","    \n","    return centered_image"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Jy7EyId5Apv","executionInfo":{"status":"ok","timestamp":1637692180765,"user_tz":-540,"elapsed":3,"user":{"displayName":"‍노혜능[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02012322631675297139"}}},"source":["def rgb2gray(rgb):\n","    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n","    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n","    return gray"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r6-EwYJuuJrb"},"source":["### DataLoader"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ak0nRWPRwbNK","executionInfo":{"status":"ok","timestamp":1637690420557,"user_tz":-540,"elapsed":770,"user":{"displayName":"‍노혜능[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02012322631675297139"}},"outputId":"14986c6e-d391-4318-eef2-179116d11186"},"source":["# import matplotlib.image as img \n","# import os\n","\n","# path = '/content/drive/Shareddrives/machine_learning_in_practice/Analog-PILGI-to-DIgital/GAN/data/printed'\n","# dataset = []\n","\n","# file_list = [os.path.join(path,file_name) for file_name in os.listdir(path)] # 45665-> augmentation 필요\n","# print(len(file_list))\n","# for fileName in file_list:\n","#     img_np = img.imread(fileName)\n","#     dataset.append(img_np)\n","#     break\n","# gray_data = rgb2gray(dataset[-1])\n","# centering_image(gray_data)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["45696\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[0.99990004, 0.99990004, 0.99990004, ..., 0.99990004, 0.99990004,\n","        0.99990004],\n","       [0.99990004, 0.99990004, 0.99990004, ..., 0.99990004, 0.99990004,\n","        0.99990004],\n","       [0.99990004, 0.99990004, 0.99990004, ..., 0.99990004, 0.99990004,\n","        0.99990004],\n","       ...,\n","       [0.99990004, 0.99990004, 0.99990004, ..., 0.99990004, 0.99990004,\n","        0.99990004],\n","       [0.99990004, 0.99990004, 0.99990004, ..., 0.99990004, 0.99990004,\n","        0.99990004],\n","       [0.99990004, 0.99990004, 0.99990004, ..., 0.99990004, 0.99990004,\n","        0.99990004]], dtype=float32)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"_dJwOyJiDWhM","executionInfo":{"status":"ok","timestamp":1637693613270,"user_tz":-540,"elapsed":1105,"user":{"displayName":"‍노혜능[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02012322631675297139"}}},"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torch import nn, optim, from_numpy\n","\n","import matplotlib.image as img \n","import os\n","\n","# pretrain용 인쇄체 dataloader 구현\n","class SyllablePrintedDataset(Dataset):\n","    def __init__(self, path): # transform 일단 없이 해봄 \n","        dataset = []\n","        # 45665 개\n","        file_list = [os.path.join(path,file_name) for file_name in os.listdir(path)] \n","        for fileName in file_list:\n","            img_np = img.imread(fileName) # img_np 의 channel : 3\n","            dataset.append(img_np)\n","            break\n","        self.dataset = dataset\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, index):\n","        if (index >= len(self.dataset)):\n","            raise IndexError()\n","        gray_data = rgb2gray(self.dataset[index])\n","        processedImg = centering_image(gray_data)\n","        return torch.cuda.FloatTensor(processedImg)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"D7DfArAP-wFz"},"source":["dataFolderPath = \"/content/drive/Shareddrives/machine_learning_in_practice/Analog-PILGI-to-DIgital/GAN/data/printed\"\n","dataset = SyllablePrintedDataset(dataFolderPath)\n","dataloader = DataLoader(dataset = dataset,\n","                          batch_size = 128,\n","                          shuffle = True) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yEL75IsxtWGp"},"source":["## WGAN_div Model"]},{"cell_type":"code","metadata":{"id":"4SSxs7ZpDWe8","executionInfo":{"status":"ok","timestamp":1637692215289,"user_tz":-540,"elapsed":2593,"user":{"displayName":"‍노혜능[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02012322631675297139"}}},"source":["import math\n","import sys\n","\n","import torchvision.transforms as transforms\n","from torchvision.utils import save_image\n","\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torch.autograd import Variable\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.autograd as autograd\n","import torch\n","\n","\n","path = '/content/drive/Shareddrives/machine_learning_in_practice/Analog-PILGI-to-DIgital/GAN/outputs/wgan_div'\n","os.makedirs(path, exist_ok=True)\n","\n","g_lossL = []\n","d_lossL = []"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"WBPY28JZohhO"},"source":["class Opt:\n","    def __init__(self, epoch=100, batch_size=64, lr=0.0002, b1=0.5, b2=0.999, n_cpu=2, latent_dim=100, img_size=64, channels=1, n_critic=5, clip_value=0.01, sample_interval=400):\n","        self.n_epochs = epoch              # number of epochs of training\n","        self.batch_size = batch_size    # size of the batches\n","        self.lr = lr                    # adam: learning rate\n","        self.b1 = b1                    # adam: decay of first order momentum of gradient\n","        self.b2 = b2                    # adam: decay of first order momentum of gradient\n","        self.n_cpu = n_cpu              # number of cpu threads to use during batch generation\n","        self.latent_dim = latent_dim    # dimensionality of the latent space\n","        self.img_size = img_size        # size of each image dimension\n","        self.channels = channels        # number of image channels\n","        self.n_critic = n_critic        # number of training steps for discriminator per iter\n","        self.clip_value = clip_value    # lower and upper clip value for disc. weights\n","        self.sample_interval = sample_interval # interval between image sampling\n","opt = Opt() \n","\n","img_shape = (opt.channels, opt.img_size, opt.img_size)\n","cuda = True if torch.cuda.is_available() else False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YcZIHr6yl5eS"},"source":["class Generator(nn.Module):\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","\n","        def block(in_feat, out_feat, normalize=True):\n","            layers = [nn.Linear(in_feat, out_feat)]\n","            if normalize:\n","                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n","            layers.append(nn.LeakyReLU(0.2, inplace=True))\n","            return layers\n","\n","        self.model = nn.Sequential(\n","            *block(opt.latent_dim, 128, normalize=False),\n","            *block(128, 256),\n","            *block(256, 512),\n","            *block(512, 1024),\n","            nn.Linear(1024, int(np.prod(img_shape))),\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, z):\n","        img = self.model(z)\n","        img = img.view(img.shape[0], *img_shape)\n","        return img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V7jfBI-6tpch"},"source":["class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","\n","        self.model = nn.Sequential(\n","            nn.Linear(int(np.prod(img_shape)), 512),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Linear(512, 256),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Linear(256, 1),\n","        )\n","\n","    def forward(self, img):\n","        img_flat = img.view(img.shape[0], -1)\n","        validity = self.model(img_flat)\n","        return validity"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QFcS2LU3tpe9"},"source":["k = 2\n","p = 6\n","\n","\n","# Initialize generator and discriminator\n","generator = Generator()\n","discriminator = Discriminator()\n","\n","if cuda:\n","    generator.cuda()\n","    discriminator.cuda()\n","\n","# Configure data loader\n","dataFolderPath = \"/content/drive/Shareddrives/machine_learning_in_practice/Analog-PILGI-to-DIgital/GAN/data/printed\"\n","dataset = SyllablePrintedDataset(dataFolderPath)\n","dataloader = DataLoader(dataset = dataset,\n","                          batch_size = 128,\n","                          shuffle = True) \n","\n","# Optimizers\n","optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n","optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n","\n","Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZI1152D0tphP","colab":{"base_uri":"https://localhost:8080/","height":418},"executionInfo":{"status":"error","timestamp":1637606634594,"user_tz":-540,"elapsed":15424,"user":{"displayName":"‍노혜능[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02012322631675297139"}},"outputId":"57bdd3d2-4947-40fe-d827-6b41f24ce1ae"},"source":["# ----------\n","#  Training\n","# ----------\n","\n","batches_done = 0\n","for epoch in range(opt.n_epochs):\n","    for i, (imgs, _) in enumerate(dataloader):\n","\n","        # Configure input\n","        real_imgs = Variable(imgs.type(Tensor), requires_grad=True)\n","\n","        # ---------------------\n","        #  Train Discriminator\n","        # ---------------------\n","\n","        optimizer_D.zero_grad()\n","\n","        # Sample noise as generator input\n","        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))\n","\n","        # Generate a batch of images\n","        fake_imgs = generator(z)\n","\n","        # Real images\n","        real_validity = discriminator(real_imgs)\n","        # Fake images\n","        fake_validity = discriminator(fake_imgs)\n","\n","        # Compute W-div gradient penalty\n","        real_grad_out = Variable(Tensor(real_imgs.size(0), 1).fill_(1.0), requires_grad=False)\n","        real_grad = autograd.grad(\n","            real_validity, real_imgs, real_grad_out, create_graph=True, retain_graph=True, only_inputs=True\n","        )[0]\n","        real_grad_norm = real_grad.view(real_grad.size(0), -1).pow(2).sum(1) ** (p / 2)\n","\n","        fake_grad_out = Variable(Tensor(fake_imgs.size(0), 1).fill_(1.0), requires_grad=False)\n","        fake_grad = autograd.grad(\n","            fake_validity, fake_imgs, fake_grad_out, create_graph=True, retain_graph=True, only_inputs=True\n","        )[0]\n","        fake_grad_norm = fake_grad.view(fake_grad.size(0), -1).pow(2).sum(1) ** (p / 2)\n","\n","        div_gp = torch.mean(real_grad_norm + fake_grad_norm) * k / 2\n","\n","        # Adversarial loss\n","        d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + div_gp\n","\n","        d_lossL.append(d_loss)\n","\n","        d_loss.backward()\n","        optimizer_D.step()\n","\n","        optimizer_G.zero_grad()\n","\n","        # Train the generator every n_critic steps\n","        if i % opt.n_critic == 0:\n","\n","            # -----------------\n","            #  Train Generator\n","            # -----------------\n","\n","            # Generate a batch of images\n","            fake_imgs = generator(z)\n","            # Loss measures generator's ability to fool the discriminator\n","            # Train on fake images\n","            fake_validity = discriminator(fake_imgs)\n","            g_loss = -torch.mean(fake_validity)\n","\n","            g_lossL.append(g_loss)\n","            \n","            g_loss.backward()\n","            optimizer_G.step()\n","\n","            print(\n","                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n","                % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n","            )\n","\n","            if batches_done % opt.sample_interval == 0:\n","                save_image(fake_imgs.data[:25], \"images/%d.png\" % batches_done, nrow=5, normalize=True)\n","\n","            batches_done += opt.n_critic"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-55fb2fe04f01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# adversarial_loss.cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \"\"\"\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \"\"\"\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 5.49 GiB (GPU 0; 11.17 GiB total capacity; 5.87 GiB already allocated; 2.50 GiB free; 8.13 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]},{"cell_type":"code","metadata":{"id":"M-jsja7cydJE"},"source":["# 학습된 모델 저장 \n","generator_out_path = '/content/drive/Shareddrives/machine_learning_in_practice/Analog-PILGI-to-DIgital/GAN/data/generator.pth'\n","torch.save(generator.state_dict(), generator_out_path)\n","\n","discriminator_out_path = '/content/drive/Shareddrives/machine_learning_in_practice/Analog-PILGI-to-DIgital/GAN/data/discriminator.pth'\n","torch.save(discriminator.state_dict(), discriminator_out_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cgjbTFrKtplP"},"source":["# g_lossL = []\n","# d_lossL = []\n","\n","import csv # csv파일로 적기 # newline 설정을 안하면 한줄마다 공백있는 줄이 생긴다. \n","with open('/content/drive/Shareddrives/machine_learning_in_practice/Analog-PILGI-to-DIgital/GAN/data/lossFile.csv', 'w', newline='') as f: \n","    writer = csv.writer(f) \n","    writer.writerow(g_lossL) \n","    writer.writerow(d_lossL) \n","    writer.writerow(info_lossL)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DP8xMdV1nmCM"},"source":["### github 커밋"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4g-2EJOFninD","executionInfo":{"status":"ok","timestamp":1637693939576,"user_tz":-540,"elapsed":406,"user":{"displayName":"‍노혜능[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02012322631675297139"}},"outputId":"14a1d1bf-d69a-4d7c-f0dc-ef4d58d88c01"},"source":["MY_GOOGLE_DRIVE_PATH = \"/content/drive/Shareddrives/machine_learning_in_practice/Analog-PILGI-to-DIgital\"\n","%cd \"{MY_GOOGLE_DRIVE_PATH}\""],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Shareddrives/machine_learning_in_practice/Analog-PILGI-to-DIgital\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JdRhqYxgl5gg","executionInfo":{"status":"ok","timestamp":1637693962375,"user_tz":-540,"elapsed":20013,"user":{"displayName":"‍노혜능[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02012322631675297139"}},"outputId":"a0313b8a-00b2-456b-a1d4-5cfec948106d"},"source":["!git config --global user.email dkwjd0824@khu.ac.kr  # 이메일 입력 ex) qhrqufdlek@naver.com\n","!git config --global user.name  hyeneung #깃헙 아이디 입력 ex)luckydipper\n","!git pull"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Already up to date.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g4NeX2iPl6Og","executionInfo":{"status":"ok","timestamp":1637691039662,"user_tz":-540,"elapsed":741,"user":{"displayName":"‍노혜능[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02012322631675297139"}},"outputId":"6574d103-133c-4cee-84ed-dd0475212fb5"},"source":["!git status"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes to be committed:\n","  (use \"git reset HEAD <file>...\" to unstage)\n","\n","\t\u001b[32mmodified:   GAN/GAN.ipynb\u001b[m\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git checkout -- <file>...\" to discard changes in working directory)\n","\n","\t\u001b[31mmodified:   \"object_detection/github_util.ipynb\\341\\204\\213\\341\\205\\264 \\341\\204\\211\\341\\205\\241\\341\\204\\207\\341\\205\\251\\341\\206\\253\\341\\204\\213\\341\\205\\264 \\341\\204\\211\\341\\205\\241\\341\\204\\207\\341\\205\\251\\341\\206\\253\"\u001b[m\n","\n"]}]},{"cell_type":"code","metadata":{"id":"ksEEkzNqmC1I"},"source":["!git add GAN/GAN.ipynb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MBM57WO1m-o4","executionInfo":{"status":"ok","timestamp":1637691044706,"user_tz":-540,"elapsed":663,"user":{"displayName":"‍노혜능[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02012322631675297139"}},"outputId":"430418ee-5576-4b30-cd95-935be82f2d34"},"source":["!git commit -m\"[FIX] dataloader\""],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[main 4f0ddfc] [FIX] dataloader\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n"," rewrite GAN/GAN.ipynb (98%)\n"]}]},{"cell_type":"code","metadata":{"id":"X5UB3iQdnSz6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637691050926,"user_tz":-540,"elapsed":1534,"user":{"displayName":"‍노혜능[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02012322631675297139"}},"outputId":"e25fa8f7-7e48-4f12-bc00-da7ae2e6c73f"},"source":["!git push"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Counting objects: 4, done.\n","Delta compression using up to 2 threads.\n","Compressing objects:  25% (1/4)   \rCompressing objects:  50% (2/4)   \rCompressing objects:  75% (3/4)   \rCompressing objects: 100% (4/4)   \rCompressing objects: 100% (4/4), done.\n","Writing objects:  25% (1/4)   \rWriting objects:  50% (2/4)   \rWriting objects:  75% (3/4)   \rWriting objects: 100% (4/4)   \rWriting objects: 100% (4/4), 2.59 KiB | 204.00 KiB/s, done.\n","Total 4 (delta 2), reused 0 (delta 0)\n","remote: Resolving deltas:   0% (0/2)\u001b[K\rremote: Resolving deltas:  50% (1/2)\u001b[K\rremote: Resolving deltas: 100% (2/2)\u001b[K\rremote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n","To https://github.com/PILGI-Analog-To-Digital/Analog-PILGI-to-DIgital.git\n","   7472db0..4f0ddfc  main -> main\n"]}]},{"cell_type":"code","metadata":{"id":"ub0x8BefzwCy"},"source":[""],"execution_count":null,"outputs":[]}]}