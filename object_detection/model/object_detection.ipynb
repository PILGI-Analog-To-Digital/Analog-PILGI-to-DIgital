{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"object_detection.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMfmb91Cjb6vnX9wH0Luggz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"CTeE8BIVVQAv"},"source":["# Object Detection\n","one stage vs two stage<br>\n","one stage : classification과 region proposal을 동시에<br>\n","two stage : classification과 region proposal을 순차적으로<br>\n","\n","one stage\n","ex) YOLO, SSD, RetinaNet\n","\n","two stage\n","ex) RCNN, Faster RCNN, Masked RCNN\n","\n","two stage model이 accuracy가 더 뛰어남\n","\n","Fast RCNN 구현."]},{"cell_type":"code","metadata":{"id":"SJBV8FHaVHC_","executionInfo":{"status":"ok","timestamp":1637638782282,"user_tz":-540,"elapsed":705,"user":{"displayName":"‍김희성[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03493957091908803854"}}},"source":["import torch\n","import os\n","import random\n","import numpy as np\n","import shutil\n","import torchvision\n","from torchvision.models.detection import FasterRCNN\n","import matplotlib.patches as patches\n","import matplotlib.pyplot as plt\n","from bs4 import BeautifulSoup\n","from PIL import Image\n","import cv2\n","import torchvision\n","from torchvision import transforms, datasets, models\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","import time\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dx2Yl7KkjZ2L","executionInfo":{"status":"ok","timestamp":1637633350879,"user_tz":-540,"elapsed":300,"user":{"displayName":"‍김희성[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03493957091908803854"}},"outputId":"8ba381ed-d605-4457-9403-80365708b2fa"},"source":["if torch.cuda.is_available():    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["No GPU available, using the CPU instead.\n"]}]},{"cell_type":"markdown","metadata":{"id":"MC6LkuQt4BVI"},"source":["# Data Augmentaion"]},{"cell_type":"code","metadata":{"id":"NIl3zZRaWGJw"},"source":["print(len(os.listdir('annotations')))\n","print(len(os.listdir('images')))\n","\n","\n","!mkdir test_images\n","!mkdir test_annotations\n","\n","\n","random.seed(1234)\n","idx = random.sample(range(853), 170)\n","\n","for img in np.array(sorted(os.listdir('images')))[idx]:\n","    shutil.move('images/'+img, 'test_images/'+img)\n","\n","for annot in np.array(sorted(os.listdir('annotations')))[idx]:\n","    shutil.move('annotations/'+annot, 'test_annotations/'+annot)\n","\n","print(len(os.listdir('annotations')))\n","print(len(os.listdir('images')))\n","print(len(os.listdir('test_annotations')))\n","print(len(os.listdir('test_images')))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QbtSJsIDZH-m"},"source":["import google"],"execution_count":null,"outputs":[]}]}