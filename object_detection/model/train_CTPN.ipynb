{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_CTPN.ipynb","provenance":[],"authorship_tag":"ABX9TyNxCspumf3zEaXP64pTfiVy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"379ph5c0h01F"},"source":["# input \\: \n","# output \\: checkpoints -> make .pth file"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1jolWDtOmvcb","executionInfo":{"status":"ok","timestamp":1637902656308,"user_tz":-540,"elapsed":5360,"user":{"displayName":"‍김희성[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03493957091908803854"}},"outputId":"fc4b8f4c-e1ef-48c7-9f90-0bea23dce83a"},"source":["!pip install import-ipynb\n","import import_ipynb"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting import-ipynb\n","  Downloading import-ipynb-0.1.3.tar.gz (4.0 kB)\n","Building wheels for collected packages: import-ipynb\n","  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-py3-none-any.whl size=2975 sha256=bd25dc075aa93948298bb3f08115c9a35e92ba8c3b93da47547f6f0a2ad493ba\n","  Stored in directory: /root/.cache/pip/wheels/b1/5e/dc/79780689896a056199b0b9f24471e3ee184fbd816df355d5f0\n","Successfully built import-ipynb\n","Installing collected packages: import-ipynb\n","Successfully installed import-ipynb-0.1.3\n"]}]},{"cell_type":"code","metadata":{"id":"ojJD3FTWhWEj"},"source":["import os\n","#os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n","import torch\n","from torch.utils.data import DataLoader\n","from torch import optim\n","import numpy as np\n","import argparse\n","\n","import config\n","from ctpn_model import CTPN_Model, RPN_CLS_Loss, RPN_REGR_Loss\n","from dataset import ICDARDataset\n","\n","\n","random_seed = 2019\n","torch.random.manual_seed(random_seed)\n","np.random.seed(random_seed)\n","\n","epochs = 2\n","lr = 1e-3\n","resume_epoch = 0\n","\n","\n","def save_checkpoint(state, epoch, loss_cls, loss_regr, loss, ext='pth'):\n","    check_path = os.path.join(config.checkpoints_dir,\n","                              f'v3_ctpn_ep{epoch:02d}_'\n","                              f'{loss_cls:.4f}_{loss_regr:.4f}_{loss:.4f}.{ext}')\n","\n","    try:\n","        torch.save(state, check_path)\n","    except BaseException as e:\n","        print(e)\n","        print('fail to save to {}'.format(check_path))\n","    print('saving to {}'.format(check_path))\n","\n","def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        m.weight.data.normal_(0.0, 0.02)\n","    elif classname.find('BatchNorm') != -1:\n","        m.weight.data.normal_(1.0, 0.02)\n","        m.bias.data.fill_(0)\n","\n","\n","if __name__ == '__main__':\n","    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","    checkpoints_weight = config.pretrained_weights\n","    print('exist pretrained ',os.path.exists(checkpoints_weight))\n","    if os.path.exists(checkpoints_weight):\n","        pretrained = False\n","\n","    dataset = ICDARDataset(config.icdar17_mlt_img_dir, config.icdar17_mlt_gt_dir)\n","    dataloader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=config.num_workers)\n","    model = CTPN_Model()\n","    model.to(device)\n","    \n","    if os.path.exists(checkpoints_weight):\n","        print('using pretrained weight: {}'.format(checkpoints_weight))\n","        cc = torch.load(checkpoints_weight, map_location=device)\n","        model.load_state_dict(cc['model_state_dict'])\n","        resume_epoch = cc['epoch']\n","    else:\n","        model.apply(weights_init)\n","\n","    params_to_uodate = model.parameters()\n","    optimizer = optim.Adam(params_to_uodate, lr=lr)\n","    \n","    critetion_cls = RPN_CLS_Loss(device)\n","    critetion_regr = RPN_REGR_Loss(device)\n","    \n","    best_loss_cls = 100\n","    best_loss_regr = 100\n","    best_loss = 100\n","    best_model = None\n","    epochs += resume_epoch\n","    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n","    \n","    for epoch in range(resume_epoch+1, epochs):\n","        print(f'Epoch {epoch}/{epochs}')\n","        print('#'*50)\n","        epoch_size = len(dataset) // 1\n","        model.train()\n","        epoch_loss_cls = 0\n","        epoch_loss_regr = 0\n","        epoch_loss = 0\n","        scheduler.step(epoch)\n","    \n","        for batch_i, (imgs, clss, regrs) in enumerate(dataloader):\n","            # print(imgs.shape)\n","            imgs = imgs.to(device)\n","            clss = clss.to(device)\n","            regrs = regrs.to(device)\n","    \n","            optimizer.zero_grad()\n","    \n","            out_cls, out_regr = model(imgs)\n","            loss_cls = critetion_cls(out_cls, clss)\n","            loss_regr = critetion_regr(out_regr, regrs)\n","    \n","            loss = loss_cls + loss_regr  # total loss\n","            loss.backward()\n","            optimizer.step()\n","    \n","            epoch_loss_cls += loss_cls.item()\n","            epoch_loss_regr += loss_regr.item()\n","            epoch_loss += loss.item()\n","            mmp = batch_i+1\n","    \n","            print(f'Ep:{epoch}/{epochs-1}--'\n","                  f'Batch:{batch_i}/{epoch_size}\\n'\n","                  f'batch: loss_cls:{loss_cls.item():.4f}--loss_regr:{loss_regr.item():.4f}--loss:{loss.item():.4f}\\n'\n","                  f'Epoch: loss_cls:{epoch_loss_cls/mmp:.4f}--loss_regr:{epoch_loss_regr/mmp:.4f}--'\n","                  f'loss:{epoch_loss/mmp:.4f}\\n')\n","    \n","        epoch_loss_cls /= epoch_size\n","        epoch_loss_regr /= epoch_size\n","        epoch_loss /= epoch_size\n","        print(f'Epoch:{epoch}--{epoch_loss_cls:.4f}--{epoch_loss_regr:.4f}--{epoch_loss:.4f}')\n","        if best_loss_cls > epoch_loss_cls or best_loss_regr > epoch_loss_regr or best_loss > epoch_loss:\n","            best_loss = epoch_loss\n","            best_loss_regr = epoch_loss_regr\n","            best_loss_cls = epoch_loss_cls\n","            best_model = model\n","            save_checkpoint({'model_state_dict': best_model.state_dict(),\n","                             'epoch': epoch},\n","                            epoch,\n","                            best_loss_cls,\n","                            best_loss_regr,\n","                            best_loss)\n","    \n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oaBXfizaiHHg","executionInfo":{"status":"ok","timestamp":1637903267239,"user_tz":-540,"elapsed":434,"user":{"displayName":"‍김희성[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03493957091908803854"}}},"source":["import os\n","os.environ['CUDA_VISIBLE_DEVICES'] = '3'"],"execution_count":7,"outputs":[]}]}