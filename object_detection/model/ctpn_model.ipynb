{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ctpn_model.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOSE/PceXsMGmbbpsoac7bq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"doF1VULwkDNt"},"source":["#Detecting Text in Natural Image model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":318},"id":"kvNiSDENj7xj","executionInfo":{"status":"error","timestamp":1637902509050,"user_tz":-540,"elapsed":453,"user":{"displayName":"‍김희성[학생](소프트웨어융합대학 소프트웨어융합학과)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03493957091908803854"}},"outputId":"1e01346b-1cf3-4765-ce88-4eb4421ec446"},"source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.models as models\n","import config\n","\n","class RPN_REGR_Loss(nn.Module):\n","    def __init__(self, device, sigma=9.0):\n","        super(RPN_REGR_Loss, self).__init__()\n","        self.sigma = sigma\n","        self.device = device\n","\n","    def forward(self, input, target):\n","        '''\n","        smooth L1 loss\n","        :param input:y_preds\n","        :param target: y_true\n","        :return:\n","        '''\n","        try:\n","            cls = target[0, :, 0]\n","            regr = target[0, :, 1:3]\n","            # apply regression to positive sample\n","            regr_keep = (cls == 1).nonzero()[:, 0]\n","            regr_true = regr[regr_keep]\n","            regr_pred = input[0][regr_keep]\n","            diff = torch.abs(regr_true - regr_pred)\n","            less_one = (diff<1.0/self.sigma).float()\n","            loss = less_one * 0.5 * diff ** 2 * self.sigma + torch.abs(1- less_one) * (diff - 0.5/self.sigma)\n","            loss = torch.sum(loss, 1)\n","            loss = torch.mean(loss) if loss.numel() > 0 else torch.tensor(0.0)\n","        except Exception as e:\n","            print('RPN_REGR_Loss Exception:', e)\n","            # print(input, target)\n","            loss = torch.tensor(0.0)\n","\n","        return loss.to(self.device)\n","\n","\n","class RPN_CLS_Loss(nn.Module):\n","    def __init__(self,device):\n","        super(RPN_CLS_Loss, self).__init__()\n","        self.device = device\n","        self.L_cls = nn.CrossEntropyLoss(reduction='none')\n","        # self.L_regr = nn.SmoothL1Loss()\n","        # self.L_refi = nn.SmoothL1Loss()\n","        self.pos_neg_ratio = 3\n","\n","    def forward(self, input, target):\n","        if config.OHEM:\n","            cls_gt = target[0][0]\n","            num_pos = 0\n","            loss_pos_sum = 0\n","\n","            # print(len((cls_gt == 0).nonzero()),len((cls_gt == 1).nonzero()))\n","\n","            if len((cls_gt == 1).nonzero())!=0:       # avoid num of pos sample is 0\n","                cls_pos = (cls_gt == 1).nonzero()[:, 0]\n","                gt_pos = cls_gt[cls_pos].long()\n","                cls_pred_pos = input[0][cls_pos]\n","                # print(cls_pred_pos.shape)\n","                loss_pos = self.L_cls(cls_pred_pos.view(-1, 2), gt_pos.view(-1))\n","                loss_pos_sum = loss_pos.sum()\n","                num_pos = len(loss_pos)\n","\n","            cls_neg = (cls_gt == 0).nonzero()[:, 0]\n","            gt_neg = cls_gt[cls_neg].long()\n","            cls_pred_neg = input[0][cls_neg]\n","\n","            loss_neg = self.L_cls(cls_pred_neg.view(-1, 2), gt_neg.view(-1))\n","            loss_neg_topK, _ = torch.topk(loss_neg, min(len(loss_neg), config.RPN_TOTAL_NUM-num_pos))\n","            loss_cls = loss_pos_sum+loss_neg_topK.sum()\n","            loss_cls = loss_cls/config.RPN_TOTAL_NUM\n","            return loss_cls.to(self.device)\n","        else:\n","            y_true = target[0][0]\n","            cls_keep = (y_true != -1).nonzero()[:, 0]\n","            cls_true = y_true[cls_keep].long()\n","            cls_pred = input[0][cls_keep]\n","            loss = F.nll_loss(F.log_softmax(cls_pred, dim=-1),\n","                              cls_true)  # original is sparse_softmax_cross_entropy_with_logits\n","            # loss = nn.BCEWithLogitsLoss()(cls_pred[:,0], cls_true.float())  # 18-12-8\n","            loss = torch.clamp(torch.mean(loss), 0, 10) if loss.numel() > 0 else torch.tensor(0.0)\n","            return loss.to(self.device)\n","\n","\n","class basic_conv(nn.Module):\n","    def __init__(self,\n","                 in_planes,\n","                 out_planes,\n","                 kernel_size,\n","                 stride=1,\n","                 padding=0,\n","                 dilation=1,\n","                 groups=1,\n","                 relu=True,\n","                 bn=True,\n","                 bias=True):\n","        super(basic_conv, self).__init__()\n","        self.out_channels = out_planes\n","        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n","        self.bn = nn.BatchNorm2d(out_planes, eps=1e-5, momentum=0.01, affine=True) if bn else None\n","        self.relu = nn.ReLU(inplace=True) if relu else None\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        if self.bn is not None:\n","            x = self.bn(x)\n","        if self.relu is not None:\n","            x = self.relu(x)\n","        return x\n","\n","\n","class CTPN_Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        base_model = models.vgg16(pretrained=False)\n","        layers = list(base_model.features)[:-1]\n","        self.base_layers = nn.Sequential(*layers)  # block5_conv3 output\n","        self.rpn = basic_conv(512, 512, 3, 1, 1, bn=False)\n","        self.brnn = nn.GRU(512,128, bidirectional=True, batch_first=True)\n","        self.lstm_fc = basic_conv(256, 512, 1, 1, relu=True, bn=False)\n","        self.rpn_class = basic_conv(512, 10 * 2, 1, 1, relu=False, bn=False)\n","        self.rpn_regress = basic_conv(512, 10 * 2, 1, 1, relu=False, bn=False)\n","\n","    def forward(self, x):\n","        x = self.base_layers(x)\n","        # rpn\n","        x = self.rpn(x)    #[b, c, h, w]\n","\n","        x1 = x.permute(0,2,3,1).contiguous()  # channels last   [b, h, w, c]\n","        b = x1.size()  # b, h, w, c\n","        x1 = x1.view(b[0]*b[1], b[2], b[3])\n","\n","        x2, _ = self.brnn(x1)\n","\n","        xsz = x.size()\n","        x3 = x2.view(xsz[0], xsz[2], xsz[3], 256)  # torch.Size([4, 20, 20, 256])\n","\n","        x3 = x3.permute(0,3,1,2).contiguous()  # channels first [b, c, h, w]\n","        x3 = self.lstm_fc(x3)\n","        x = x3\n","\n","        cls = self.rpn_class(x)\n","        regr = self.rpn_regress(x)\n","\n","        cls = cls.permute(0,2,3,1).contiguous()\n","        regr = regr.permute(0,2,3,1).contiguous()\n","\n","        cls = cls.view(cls.size(0), cls.size(1)*cls.size(2)*10, 2)\n","        regr = regr.view(regr.size(0), regr.size(1)*regr.size(2)*10, 2)\n","\n","        return cls, regr"],"execution_count":2,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-525ff4d06ac3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mImportError\u001b[0m: cannot import name 'model' from 'torch.nn' (/usr/local/lib/python3.7/dist-packages/torch/nn/__init__.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","metadata":{"id":"TaTkMDjpkQ9n"},"source":[""],"execution_count":null,"outputs":[]}]}